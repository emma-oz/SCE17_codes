{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation  \n",
    "from keras.layers import LSTM, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, LSTM,TimeDistributed, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Nadam\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_training = pickle.load(open(\"../data/X_train.pickle\",\"rb\"))\n",
    "# Y_training = pickle.load(open(\"../data/Y_train.pickle\",\"rb\"))\n",
    "# X_testing = pickle.load(open(\"../data/X_test.pickle\",\"rb\"))\n",
    "# Y_testing = pickle.load(open(\"../data/Y_test.pickle\",\"rb\"))\n",
    "\n",
    "# X_training_un = pickle.load(open(\"../data/X_train_un.pickle\",\"rb\"))\n",
    "# Y_training_un = pickle.load(open(\"../data/Y_train_un.pickle\",\"rb\"))\n",
    "# X_testing_un = pickle.load(open(\"../data/X_test_un.pickle\",\"rb\"))\n",
    "# Y_testing_un = pickle.load(open(\"../data/Y_test_un.pickle\",\"rb\"))\n",
    "\n",
    "# X_training = np.concatenate((X_training, X_training_un), axis=0)\n",
    "# Y_training = np.concatenate((Y_training, Y_training_un), axis=0)\n",
    "# X_testing = np.concatenate((X_testing, X_testing_un), axis=0)\n",
    "# Y_testing = np.concatenate((Y_testing, Y_testing_un), axis=0)\n",
    "\n",
    "# # Centering\n",
    "# mux = np.mean(X_training, axis=0)\n",
    "# stdx = np.std(X_training, axis=0)\n",
    "# X_training = (X_training - mux)/stdx\n",
    "# X_testing = (X_testing - mux)/stdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read and pre-processed\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data2/f_D100_ush'\n",
    "\n",
    "X_training = np.load(os.path.join(data_dir, \"X_train.npy\"))\n",
    "Y_training = np.load(os.path.join(data_dir, \"Y_train.npy\"))\n",
    "\n",
    "X_val = np.load(os.path.join(data_dir, \"X_val.npy\"))\n",
    "Y_val = np.load(os.path.join(data_dir, \"Y_val.npy\"))\n",
    "\n",
    "X_testing = np.load(os.path.join(data_dir, \"X_test.npy\"))\n",
    "Y_testing = np.load(os.path.join(data_dir, \"Y_test.npy\"))\n",
    "\n",
    "\n",
    "ds_rate = 1\n",
    "X_training = np.array([val for key, val in enumerate(X_training) if key%ds_rate==0])\n",
    "Y_training = np.array([val for key, val in enumerate(Y_training) if key%ds_rate==0])\n",
    "\n",
    "X_val = np.array([val for key, val in enumerate(X_val) if key%ds_rate==0])\n",
    "Y_val = np.array([val for key, val in enumerate(Y_val) if key%ds_rate==0])\n",
    "\n",
    "X_testing = np.array([val for key, val in enumerate(X_testing) if key%ds_rate==0])\n",
    "Y_testing = np.array([val for key, val in enumerate(Y_testing) if key%ds_rate==0])\n",
    "\n",
    "# Centering and Normalizing data\n",
    "\n",
    "mux = np.mean(X_training, axis=0)\n",
    "stdx = np.std(X_training, axis=0)\n",
    "X_training = (X_training - mux)/stdx\n",
    "X_val = (X_val - mux)/stdx\n",
    "X_testing = (X_testing - mux)/stdx\n",
    "\n",
    "print(\"Data read and pre-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncJAkdf4fFUO3xv2wX8wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f613818dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_training)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(time_steps = 30, data_dim = 50):\n",
    "    in_neurons = 50\n",
    "    out_neurons= 1\n",
    "    hidden_neurons = 20\n",
    "    \n",
    "    # model = Sequential()\n",
    "    # model.add(LSTM(hidden_neurons, input_shape=(time_steps, data_dim), return_sequences=True, activation=\"relu\"))\n",
    "    # # model.add(Flatten())\n",
    "    # model.add(LSTM(25, return_sequences=False, activation=\"relu\"))\n",
    "    # model.add(Dense(out_neurons, input_shape = (time_steps, hidden_neurons), activation=\"linear\"))\n",
    "    # # model.add(Activation(\"linear\"))\n",
    "    # nadam = Nadam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    # model.compile(loss=\"mean_squared_error\", optimizer=nadam)\n",
    "    # L=len(X_training)\n",
    "\n",
    "    layer1Dim = 256#100\n",
    "    layer2Dim = 50\n",
    "    inputs = Input(shape=(time_steps, data_dim))\n",
    "#     batchNorm1 = BatchNormalization( name = \"batch_norm_1\")(inputs)\n",
    "    lstm1 = LSTM(layer1Dim, return_sequences = True, name = 'lstm_1', activation=\"tanh\")(inputs)\n",
    "#     batchNorm2 = BatchNormalization( name = \"batch_norm_2\")(lstm1)\n",
    "    dropout1 = Dropout(0.0)(lstm1)\n",
    "    lstm2 = LSTM(layer2Dim, return_sequences = True, name = 'lstm_2', activation=\"relu\")(dropout1)\n",
    "    batchNorm3 = BatchNormalization( name = \"batch_norm_3\")(lstm2)\n",
    "    flatten = Flatten()(lstm1)\n",
    "    dense1 = Dense(512, activation=\"relu\", name=\"Dense1\")(flatten)\n",
    "    dropout2 = Dropout(0.0)(dense1)\n",
    "    output = Dense(1, activation='linear', name=\"Output\")(dropout2)\n",
    "    model = Model(inputs = inputs, outputs = output)\n",
    "    \n",
    "    op = dense1._keras_shape\n",
    "    print(op[0], op[1])\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model2(data_dim = 50):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_shape=(data_dim,), output_dim=256))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(output_dim=128))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(output_dim=64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(output_dim=1))   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(X, Y, time_steps=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X)-time_steps-1):\n",
    "        a = X[i:(i+time_steps)]\n",
    "        dataX.append(a)\n",
    "        a = Y[(i+time_steps)]\n",
    "        dataY.append(a)  #dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_steps = 30\n",
    "trainX, trainY = create_dataset(X_training, Y_training, time_steps)\n",
    "valX, valY = create_dataset(X_val, Y_val, time_steps)\n",
    "testX, testY = create_dataset(X_testing, Y_testing, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25694, 100) (25694,)\n",
      "(25663, 30, 100) (25663,)\n",
      "(1742, 30, 100) (1742,)\n",
      "(10981, 30, 100) (10981,)\n"
     ]
    }
   ],
   "source": [
    "print(X_training.shape, Y_training.shape)\n",
    "print(trainX.shape, trainY.shape)\n",
    "print(testX.shape, testY.shape)\n",
    "print(valX.shape, valY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Training\n",
    "# n_epochs = 20\n",
    "# time_steps = 5\n",
    "# data_dim = X_training.shape[1]\n",
    "# rmses = np.zeros((time_steps, n_epochs))\n",
    "# optimizer = optimizers.RMSprop(lr=1e-5)#, beta_1=0.9, beta_2=0.999, epsilon=1e-08)#, schedule_decay=0.004)\n",
    "\n",
    "# for time_step in range(1,time_steps+1):\n",
    "#     model = get_model(time_steps, data_dim)\n",
    "#     model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "#     for i in range(n_epochs):\n",
    "#         for j in range(L-time_steps):\n",
    "#             X_train = np.reshape(X_training[j:j+time_steps,:], [1, time_steps, data_dim])\n",
    "#             Y_train = np.reshape(Y_training[j+time_steps], [1, 1])\n",
    "#             model.fit(X_train, Y_train, verbose=0, epochs=1)\n",
    "#         rmse = get_rmse(model, X_testing, Y_testing, time_steps)\n",
    "#         print(\"Time-Step {}/{} \\t Epoch {}/{} \\t RMSE = {}\".format(time_step, time_steps, i+1, n_epochs, rmse))\n",
    "#         rmses[time_step-1, i] = rmse\n",
    "# #     print(\"Time Step {} done\".format(time_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 256)           365568    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 512)               3932672   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,298,753\n",
      "Trainable params: 4,298,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "data_dim = X_training.shape[1]\n",
    "optimizer = optimizers.Adam()#, beta_1=0.9, beta_2=0.999, epsilon=1e-08)#, schedule_decay=0.004)\n",
    "model = get_model(time_steps, data_dim)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "print(model.summary())\n",
    "batch_size = 20\n",
    "L=len(X_training)\n",
    "\n",
    "# for i in range(n_epochs):\n",
    "#     for j in range(0, L, batch_size):\n",
    "#         X_train = np.reshape(X_training[j:j+batch_size,:], [1, batch_size, data_dim])\n",
    "#         Y_train = np.reshape(Y_training[j+batch_size], [1, 1])\n",
    "val_data = (valX, valY)\n",
    "# model.fit(X_training, Y_training, batch_size=batch_size, epochs=20, validation_data=val_data)\n",
    "# rmse = get_rmse(model, X_testing, Y_testing, time_steps)\n",
    "# print(\"Time-Step {}/{} \\t Epoch {}/{} \\t RMSE = {}\".format(time_step, time_steps, i+1, n_epochs, rmse))\n",
    "# rmses[time_step-1, i] = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25663 samples, validate on 10981 samples\n",
      "Epoch 1/200\n",
      " 2700/25663 [==>...........................] - ETA: 1:31 - loss: 24.1733"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-246f36a2cfb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model.fit(X_training, Y_training, batch_size=batch_size, epochs=50, validation_data=val_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit(X_training, Y_training, batch_size=batch_size, epochs=50, validation_data=val_data)\n",
    "\n",
    "model.fit(trainX, trainY, batch_size=batch_size, epochs=200, validation_data=val_data, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "preds = model.predict(testX)\n",
    "# rmse = np.sqrt(np.mean((np.array(preds) - testY)**2))\n",
    "rmse = np.sqrt(mean_squared_error(preds, testY))\n",
    "print(\"RMSE\", rmse)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(preds,'o',color='blue',markersize=2,mew=0.5,mec='blue',markerfacecolor='none')\n",
    "plt.plot(testY,'r',linewidth=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Save model\n",
    "model.save('model_lstm_S7_D100.h5')\n",
    "\n",
    "# Load saved model\n",
    "# model = load_model('model_mlp_time_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rmse(model, X_testing, Y_testing, time_steps):\n",
    "    preds=[]\n",
    "    for j in range(len(X_testing)-time_steps):\n",
    "        predicted = model.predict(np.reshape(X_testing[j:j+time_steps, :], [1, time_steps, X_testing.shape[1]]))\n",
    "        preds.append(predicted[-1])\n",
    "\n",
    "    Y_tst = Y_testing[time_steps:]\n",
    "    rmse = np.sqrt(np.mean((np.array(preds) - Y_tst)**2))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for j in range(len(X_testing)-time_steps):\n",
    "    predicted = model.predict(np.reshape(X_testing[j:j+time_steps, :], [1, time_steps, X_testing.shape[1]]))\n",
    "#     predicted = np.reshape(predicted, [10])\n",
    "    preds.append(predicted[-1])\n",
    "    \n",
    "Y_tst = Y_testing[time_steps:]\n",
    "rmse = np.sqrt(np.mean((np.array(preds) - Y_tst)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(preds,'o',color='blue',markersize=2,mew=0.5,mec='blue',markerfacecolor='none')\n",
    "plt.plot(Y_testing,'r',linewidth=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('mlp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.load_model('mlp.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
