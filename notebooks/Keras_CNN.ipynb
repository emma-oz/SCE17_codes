{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmacreeves/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import keras.backend as K\n",
    "#import xgboost as xgb\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential, load_model  \n",
    "from keras.layers.core import Dense, Activation  \n",
    "from keras.layers import LSTM, Flatten, Dropout, Conv1D, MaxPooling1D, Convolution1D,\\\n",
    "                         Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, LSTM,TimeDistributed, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Nadam\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_training = pickle.load(open(\"X_train.pickle\",\"rb\"))\n",
    "# Y_training = pickle.load(open(\"Y_train.pickle\",\"rb\"))\n",
    "# X_testing = pickle.load(open(\"X_test.pickle\",\"rb\"))\n",
    "# Y_testing = pickle.load(open(\"Y_test.pickle\",\"rb\"))\n",
    "\n",
    "# X_training_un = pickle.load(open(\"X_train_un.pickle\",\"rb\"))\n",
    "# Y_training_un = pickle.load(open(\"Y_train_un.pickle\",\"rb\"))\n",
    "# X_testing_un = pickle.load(open(\"X_test_un.pickle\",\"rb\"))\n",
    "# Y_testing_un = pickle.load(open(\"Y_test_un.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "data_dir = '../data2/Mud_lowf_15dB/1train'\n",
    "\n",
    "X_training = np.load(os.path.join(data_dir, \"X_train.p\"))#\"../data2/X_train_f100.npy\")\n",
    "Y_training = np.load(os.path.join(data_dir, \"Y_train.p\"))#\"../data2/Y_train_f100.npy\")\n",
    "\n",
    "X_val = np.load(os.path.join(data_dir, \"X_val.p\"))#\"../data2/X_val_f100.npy\")\n",
    "Y_val = np.load(os.path.join(data_dir, \"Y_val.p\"))#\"../data2/Y_val_f100.npy\")\n",
    "\n",
    "X_testing = np.load(os.path.join(data_dir, \"X_test.p\"))#\"../data2/X_test_f100.npy\")\n",
    "Y_testing = np.load(os.path.join(data_dir, \"Y_test.p\"))#\"../data2/Y_test_f100.npy\")\n",
    "\n",
    "# X_training_un = pickle.load(open(\"X_train_un.pickle\",\"rb\"))\n",
    "# Y_training_un = pickle.load(open(\"Y_train_un.pickle\",\"rb\"))\n",
    "# X_testing_un = pickle.load(open(\"X_test_un.pickle\",\"rb\"))\n",
    "# Y_testing_un = pickle.load(open(\"Y_test_un.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "# X_training = np.concatenate((X_training, X_training_un), axis=0)\n",
    "# Y_training = np.concatenate((Y_training, Y_training_un), axis=0)\n",
    "# X_val = X_testing\n",
    "# Y_val = Y_testing\n",
    "# X_testing = np.concatenate((X_testing, X_testing_un), axis=0)\n",
    "# Y_testing = np.concatenate((Y_testing, Y_testing_un), axis=0)\n",
    "\n",
    "\n",
    "# Centering and Normalizing data\n",
    "\n",
    "\n",
    "# X_training = X_training[0:10]\n",
    "# Y_training = Y_training[0:10]\n",
    "\n",
    "mux = np.mean(X_training, axis=0)\n",
    "stdx = np.std(X_training, axis=0)\n",
    "X_training = (X_training - mux)/stdx\n",
    "X_val = (X_val - mux)/stdx\n",
    "X_testing = (X_testing - mux)/stdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 15, 76, 2), (1500, 15, 76, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training.shape, X_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqcRS9Jjfs/8yj1kchfXe0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d081c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_training)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(batch_size, data_dim = 100):\n",
    "    nb_filters = 200\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(input_shape = (data_dim, 1), filters = nb_filters, \n",
    "#                      kernel_size = 10, activation='tanh', name=\"Conv1\"))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Conv1D(filters = nb_filters, kernel_size = 5, \n",
    "#                      activation='relu', name=\"Conv2\"))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(2048, activation='relu', name=\"Dense1\"))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1024, activation='relu', name=\"Dense2\"))\n",
    "#     model.add(Dense(1))\n",
    "    \n",
    "#     inputs = Input(shape = (data_dim, 1))\n",
    "#     conv_1 = Convolution1D(filters = 512, kernel_size = 16,\n",
    "#                     activation='tanh', name=\"Conv1\")(inputs)\n",
    "#     maxpool_1 = MaxPooling1D(name=\"maxpool1\")(conv_1)\n",
    "# #     batch_norm1 = BatchNormalization( name = \"batch_norm_1\")(maxpool_1)\n",
    "#     conv_2 = Convolution1D(filters = 256, kernel_size = 8, \n",
    "#                      activation='relu', name=\"Conv2\")(maxpool_1)\n",
    "#     maxpool_2 = MaxPooling1D(name=\"maxpool2\")(conv_2)\n",
    "# #     batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(maxpool_2)\n",
    "    \n",
    "#     conv_3 = Convolution1D(filters = nb_filters, kernel_size = 2, \n",
    "#                      activation='relu', name=\"Conv3\")(maxpool_2)\n",
    "#     maxpool_3 = MaxPooling1D(name=\"maxpool3\")(conv_3)\n",
    "# #     batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(maxpool_2)\n",
    "    \n",
    "#     flatten = Flatten()(maxpool_2)\n",
    "#     dense_1 = Dense(1024, activation='relu', name=\"Dense1\")(flatten)\n",
    "# #     dropout_1 = Dropout(0.2)(dense_1)\n",
    "#     dense_2 = Dense(512, activation='relu', name=\"Dense2\")(dense_1)\n",
    "# #     dropout_1 = Dropout(0.2)(dense_2)\n",
    "#     output = Dense(1, name=\"output\")(dense_2)\n",
    "#     model = Model(inputs = inputs, output = output)\n",
    "\n",
    "    inputs = Input(shape = (15,76,2))\n",
    "    conv_1 = Convolution2D(filters = 512, kernel_size = (7,7),\n",
    "                    activation='tanh', name=\"Conv1\")(inputs)\n",
    "    maxpool_1 = MaxPooling2D(name=\"maxpool1\")(conv_1)\n",
    "#     batch_norm1 = BatchNormalization( name = \"batch_norm_1\")(maxpool_1)\n",
    "    conv_2 = Convolution2D(filters = 256, kernel_size = (3,3), \n",
    "                     activation='relu', name=\"Conv2\")(conv_1)\n",
    "    maxpool_2 = MaxPooling2D(name=\"maxpool2\")(conv_2)\n",
    "#     batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(maxpool_2)\n",
    "    \n",
    "    conv_3 = Convolution2D(filters = nb_filters, kernel_size = (3,3), \n",
    "                     activation='relu', name=\"Conv3\")(conv_2)\n",
    "    maxpool_3 = MaxPooling2D(name=\"maxpool3\")(conv_3)\n",
    "#     batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(maxpool_2)\n",
    "    \n",
    "    flatten = Flatten()(maxpool_3)\n",
    "    dense_1 = Dense(1024, activation='relu', name=\"Dense1\")(flatten)\n",
    "#     dropout_1 = Dropout(0.2)(dense_1)\n",
    "    dense_2 = Dense(512, activation='relu', name=\"Dense2\")(dense_1)\n",
    "#     dropout_1 = Dropout(0.2)(dense_2)\n",
    "    output = Dense(1, name=\"output\")(dense_2)\n",
    "    model = Model(inputs = inputs, output = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/emmacreeves/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/emmacreeves/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmacreeves/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "data_dim = X_training.shape[1]\n",
    "batch_size = 20\n",
    "L=len(X_training)\n",
    "n_Iter = int(L/batch_size)\n",
    "\n",
    "optimizer = optimizers.Adadelta()#, beta_1=0.9, beta_2=0.999, epsilon=1e-08)#, schedule_decay=0.004)\n",
    "model = get_model(batch_size, data_dim)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4,\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "# val_data = (np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1)), Y_val)\n",
    "# Y_train = np.reshape( Y_training, (L, 1, 1) )\n",
    "# X_train = np.reshape( X_training, (L, X_training.shape[1], 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 15, 76, 2)         0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 9, 70, 512)        50688     \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 7, 68, 256)        1179904   \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 5, 66, 200)        461000    \n",
      "_________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)      (None, 2, 33, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13200)             0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 1024)              13517824  \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 15,734,729\n",
      "Trainable params: 15,734,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 450 samples\n",
      "Epoch 1/50\n",
      " 520/1050 [=============>................] - ETA: 44s - loss: 18.9120"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6f132d2efe8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#           validation_data=(X_testing, Y_testing),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_training, y=Y_training, batch_size=batch_size, epochs=n_epochs, \n",
    "          validation_split=0.3,\n",
    "#           validation_data=(X_testing, Y_testing), \n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# model.save('model_1D_CNN.h5')\n",
    "\n",
    "# Load saved model\n",
    "# model = load_model('model_mlp_time_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 components, full data, n_estimators = 100, reg:gamma\n",
    "# preds = model.predict(np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1)))\n",
    "# rmse = np.sqrt(mean_squared_error(preds, Y_val)) #np.sqrt(np.mean((preds-Y_testing)**2))\n",
    "# print(\"Val RMSE:\", rmse)\n",
    "\n",
    "preds = model.predict(X_testing)#np.reshape(X_testing, (X_testing.shape[0], X_testing.shape[1], 1)))\n",
    "plt.plot(preds,'o',color='blue',markersize=2,mew=0.5,mec='blue',markerfacecolor='none')\n",
    "plt.plot(Y_testing,'r',linewidth=1.0)\n",
    "plt.legend(['Precitions', 'Ground Truth'])\n",
    "plt.show()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(preds, Y_testing)) #np.sqrt(np.mean((preds-Y_testing)**2))\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_1D_CNN.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
