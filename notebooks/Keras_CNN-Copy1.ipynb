{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akpurohi/.conda/envs/python_env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import keras.backend as K\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential, load_model  \n",
    "from keras.layers.core import Dense, Activation  \n",
    "from keras.layers import LSTM, Flatten, Dropout, Conv1D, MaxPooling1D, Convolution1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, LSTM,TimeDistributed, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Nadam\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_training = pickle.load(open(\"X_train.pickle\",\"rb\"))\n",
    "# Y_training = pickle.load(open(\"Y_train.pickle\",\"rb\"))\n",
    "# X_testing = pickle.load(open(\"X_test.pickle\",\"rb\"))\n",
    "# Y_testing = pickle.load(open(\"Y_test.pickle\",\"rb\"))\n",
    "\n",
    "# X_training_un = pickle.load(open(\"X_train_un.pickle\",\"rb\"))\n",
    "# Y_training_un = pickle.load(open(\"Y_train_un.pickle\",\"rb\"))\n",
    "# X_testing_un = pickle.load(open(\"X_test_un.pickle\",\"rb\"))\n",
    "# Y_testing_un = pickle.load(open(\"Y_test_un.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "data_dir = '../data2'\n",
    "\n",
    "X_training = np.load(os.path.join(data_dir, \"X_train_f100.npy\"))#\"../data2/X_train_f100.npy\")\n",
    "Y_training = np.load(os.path.join(data_dir, \"Y_train_f100.npy\"))#\"../data2/Y_train_f100.npy\")\n",
    "\n",
    "X_val = np.load(os.path.join(data_dir, \"X_val_f100.npy\"))#\"../data2/X_val_f100.npy\")\n",
    "Y_val = np.load(os.path.join(data_dir, \"Y_val_f100.npy\"))#\"../data2/Y_val_f100.npy\")\n",
    "\n",
    "X_testing = np.load(os.path.join(data_dir, \"X_test_f100.npy\"))#\"../data2/X_test_f100.npy\")\n",
    "Y_testing = np.load(os.path.join(data_dir, \"Y_test_f100.npy\"))#\"../data2/Y_test_f100.npy\")\n",
    "\n",
    "# X_training_un = pickle.load(open(\"X_train_un.pickle\",\"rb\"))\n",
    "# Y_training_un = pickle.load(open(\"Y_train_un.pickle\",\"rb\"))\n",
    "# X_testing_un = pickle.load(open(\"X_test_un.pickle\",\"rb\"))\n",
    "# Y_testing_un = pickle.load(open(\"Y_test_un.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "# X_training = np.concatenate((X_training, X_training_un), axis=0)\n",
    "# Y_training = np.concatenate((Y_training, Y_training_un), axis=0)\n",
    "# X_val = X_testing\n",
    "# Y_val = Y_testing\n",
    "# X_testing = np.concatenate((X_testing, X_testing_un), axis=0)\n",
    "# Y_testing = np.concatenate((Y_testing, Y_testing_un), axis=0)\n",
    "\n",
    "\n",
    "# Centering and Normalizing data\n",
    "\n",
    "\n",
    "# X_training = X_training[0:10]\n",
    "# Y_training = Y_training[0:10]\n",
    "\n",
    "mux = np.mean(X_training, axis=0)\n",
    "stdx = np.std(X_training, axis=0)\n",
    "X_training = (X_training - mux)/stdx\n",
    "X_val = (X_val - mux)/stdx\n",
    "X_testing = (X_testing - mux)/stdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_training)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(batch_size, data_dim = 100):\n",
    "    nb_filters = 200\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(input_shape = (data_dim, 1), filters = nb_filters, \n",
    "#                      kernel_size = 10, activation='tanh', name=\"Conv1\"))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Conv1D(filters = nb_filters, kernel_size = 5, \n",
    "#                      activation='relu', name=\"Conv2\"))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(2048, activation='relu', name=\"Dense1\"))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1024, activation='relu', name=\"Dense2\"))\n",
    "#     model.add(Dense(1))\n",
    "    \n",
    "    inputs = Input(shape = (data_dim, 1))\n",
    "    conv_1 = Convolution1D(filters = nb_filters, kernel_size = 3,\n",
    "                    activation='tanh', name=\"Conv1\")(inputs)\n",
    "    maxpool_1 = MaxPooling1D(name=\"maxpool1\")(conv_1)\n",
    "    batch_norm1 = BatchNormalization( name = \"batch_norm_1\")(maxpool_1)\n",
    "    conv_2 = Convolution1D(filters = nb_filters, kernel_size = 2, \n",
    "                     activation='relu', name=\"Conv2\")(batch_norm1)\n",
    "    maxpool_2 = MaxPooling1D(name=\"maxpool2\")(conv_2)\n",
    "    batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(maxpool_2)\n",
    "    \n",
    "    conv_3 = Convolution1D(filters = nb_filters, kernel_size = 2, \n",
    "                     activation='relu', name=\"Conv3\")(batch_norm2)\n",
    "    maxpool_3 = MaxPooling1D(name=\"maxpool3\")(conv_3)\n",
    "#     batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(maxpool_2)\n",
    "    \n",
    "    flatten = Flatten()(maxpool_3)\n",
    "    dense_1 = Dense(1024, activation='relu', name=\"Dense1\")(flatten)\n",
    "    dropout_1 = Dropout(0.4)(dense_1)\n",
    "    dense_2 = Dense(512, activation='relu', name=\"Dense2\")(dropout_1)\n",
    "    dropout_1 = Dropout(0.4)(dense_2)\n",
    "    output = Dense(1, name=\"output\")(dense_2)\n",
    "    model = Model(inputs = inputs, output = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 16, 1)             0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv1D)               (None, 15, 200)           600       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling1D)      (None, 7, 200)            0         \n",
      "_________________________________________________________________\n",
      "batch_norm_1 (BatchNormaliza (None, 7, 200)            800       \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv1D)               (None, 6, 200)            80200     \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling1D)      (None, 3, 200)            0         \n",
      "_________________________________________________________________\n",
      "batch_norm_2 (BatchNormaliza (None, 3, 200)            800       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 1024)              615424    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,223,137\n",
      "Trainable params: 1,222,337\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akpurohi/.conda/envs/python_env/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25694 samples, validate on 11012 samples\n",
      "Epoch 1/50\n",
      "25694/25694 [==============================] - 69s 3ms/step - loss: 25.1263 - val_loss: 31.7733\n",
      "Epoch 2/50\n",
      "25694/25694 [==============================] - 57s 2ms/step - loss: 11.8638 - val_loss: 43.2634\n",
      "Epoch 3/50\n",
      "25694/25694 [==============================] - 56s 2ms/step - loss: 10.7171 - val_loss: 27.6724\n",
      "Epoch 4/50\n",
      "25694/25694 [==============================] - 60s 2ms/step - loss: 9.8121 - val_loss: 30.3202\n",
      "Epoch 5/50\n",
      "25694/25694 [==============================] - 67s 3ms/step - loss: 9.1218 - val_loss: 35.1738\n",
      "Epoch 6/50\n",
      "25694/25694 [==============================] - 60s 2ms/step - loss: 8.6094 - val_loss: 29.1957\n",
      "Epoch 7/50\n",
      "25694/25694 [==============================] - 57s 2ms/step - loss: 8.2801 - val_loss: 27.9545\n",
      "Epoch 8/50\n",
      "25694/25694 [==============================] - 61s 2ms/step - loss: 7.8571 - val_loss: 37.4318\n",
      "Epoch 9/50\n",
      "25694/25694 [==============================] - 65s 3ms/step - loss: 7.5249 - val_loss: 32.3486\n",
      "Epoch 10/50\n",
      "25694/25694 [==============================] - 56s 2ms/step - loss: 7.2068 - val_loss: 29.5803\n",
      "Epoch 11/50\n",
      "25694/25694 [==============================] - 55s 2ms/step - loss: 6.9729 - val_loss: 29.0151\n",
      "Epoch 12/50\n",
      "25694/25694 [==============================] - 65s 3ms/step - loss: 6.6914 - val_loss: 33.6824\n",
      "Epoch 13/50\n",
      "25694/25694 [==============================] - 58s 2ms/step - loss: 6.5181 - val_loss: 30.5500\n",
      "Epoch 14/50\n",
      "25694/25694 [==============================] - 56s 2ms/step - loss: 6.2757 - val_loss: 27.4950\n",
      "Epoch 15/50\n",
      " 1080/25694 [>.............................] - ETA: 55s - loss: 5.6250"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "data_dim = X_training.shape[1]\n",
    "batch_size = 20\n",
    "L=len(X_training)\n",
    "n_Iter = int(L/batch_size)\n",
    "\n",
    "optimizer = optimizers.RMSprop()#, beta_1=0.9, beta_2=0.999, epsilon=1e-08)#, schedule_decay=0.004)\n",
    "model = get_model(batch_size, data_dim)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "val_data = (np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1)), Y_val)\n",
    "Y_train = np.reshape( Y_training, (L, 1, 1) )\n",
    "X_train = np.reshape( X_training, (L, X_training.shape[1], 1) )\n",
    "\n",
    "\n",
    "\n",
    "# for epoch in range(n_epochs):\n",
    "#     pos = 0\n",
    "#     for itr in range(n_Iter):\n",
    "# #         trainX = X_training[pos: pos+batch_size]\n",
    "# #         trainY = Y_training[pos: pos+batch_size]\n",
    "#         trainX = np.reshape(X_training[pos: pos+batch_size], (1, batch_size, X_training.shape[1]))\n",
    "#         trainY = np.reshape(Y_training[pos: pos+batch_size], (1, batch_size, 1))\n",
    "#         model.fit(trainX, trainY, validation_data = val_data)\n",
    "#         pos += batch_size\n",
    "\n",
    "model.fit(x=X_train, y=Y_training, batch_size=batch_size, epochs=n_epochs, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# model.save('model_mlp_time_data.h5')\n",
    "\n",
    "# Load saved model\n",
    "# model = load_model('model_mlp_time_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 100 components, full data, n_estimators = 100, reg:gamma\n",
    "preds = model.predict(np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1)))\n",
    "rmse = np.sqrt(mean_squared_error(preds, Y_val)) #np.sqrt(np.mean((preds-Y_testing)**2))\n",
    "print(\"Val RMSE:\", rmse)\n",
    "\n",
    "preds = model.predict(np.reshape(X_testing, (X_testing.shape[0], X_testing.shape[1], 1)))\n",
    "plt.plot(preds,'o',color='blue',markersize=2,mew=0.5,mec='blue',markerfacecolor='none')\n",
    "plt.plot(Y_testing,'r',linewidth=1.0)\n",
    "plt.legend(['Precitions', 'Ground Truth'])\n",
    "plt.show()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(preds, Y_testing)) #np.sqrt(np.mean((preds-Y_testing)**2))\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
