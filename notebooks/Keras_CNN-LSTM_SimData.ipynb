{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmacreeves/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import keras.backend as K\n",
    "# import xgboost as xgb\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential, load_model  \n",
    "from keras.layers.core import Dense, Activation  \n",
    "from keras.layers import Input, Dense, LSTM, Flatten, Dropout, Reshape,\\\n",
    "                         Conv1D, MaxPooling1D, Convolution1D,\\\n",
    "                         Convolution2D, MaxPooling2D,\\\n",
    "                         Convolution3D, MaxPooling3D\n",
    "from keras.models import Sequential\n",
    "# from keras.layers import Input, Dense, LSTM, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "# from keras.optimizers import Nadam\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data2/Mud_lowf_15dB/1train'\n",
    "\n",
    "X_training = np.load(os.path.join(data_dir, \"X_train.p\"))#\"../data2/X_train_f100.npy\")\n",
    "Y_training = np.load(os.path.join(data_dir, \"Y_train.p\"))#\"../data2/Y_train_f100.npy\")\n",
    "\n",
    "X_val = np.load(os.path.join(data_dir, \"X_val.p\"))#\"../data2/X_val_f100.npy\")\n",
    "Y_val = np.load(os.path.join(data_dir, \"Y_val.p\"))#\"../data2/Y_val_f100.npy\")\n",
    "\n",
    "X_testing = np.load(os.path.join(data_dir, \"X_test.p\"))#\"../data2/X_test_f100.npy\")\n",
    "Y_testing = np.load(os.path.join(data_dir, \"Y_test.p\"))#\"../data2/Y_test_f100.npy\")\n",
    "\n",
    "X_training = np.concatenate( (X_training, X_val), axis=0 )\n",
    "Y_training = np.concatenate( (Y_training, Y_val), axis=0 )\n",
    "\n",
    "# Centering and Normalizing data\n",
    "mux = np.mean(X_training, axis=0)\n",
    "stdx = np.std(X_training, axis=0)\n",
    "X_training = (X_training - mux)/stdx\n",
    "X_val = (X_val - mux)/stdx\n",
    "X_testing = (X_testing - mux)/stdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(0):\n",
    "    data_dir = '../data2/5dBsim'\n",
    "\n",
    "    X_training = np.load(os.path.join(data_dir, \"X_train.npy\"))#\"../data2/X_train_f100.npy\")\n",
    "    Y_training = np.load(os.path.join(data_dir, \"Y_train.npy\"))#\"../data2/Y_train_f100.npy\")\n",
    "\n",
    "    X_val = np.load(os.path.join(data_dir, \"X_val.npy\"))#\"../data2/X_val_f100.npy\")\n",
    "    Y_val = np.load(os.path.join(data_dir, \"Y_val.npy\"))#\"../data2/Y_val_f100.npy\")\n",
    "\n",
    "    X_testing = np.load(os.path.join(data_dir, \"X_test.npy\"))#\"../data2/X_test_f100.npy\")\n",
    "    Y_testing = np.load(os.path.join(data_dir, \"Y_test.npy\"))#\"../data2/Y_test_f100.npy\")\n",
    "\n",
    "    # Centering and Normalizing data\n",
    "    mux = np.mean(X_training, axis=0)\n",
    "    stdx = np.std(X_training, axis=0)\n",
    "    X_training = (X_training - mux)/stdx\n",
    "    X_val = (X_val - mux)/stdx\n",
    "    X_testing = (X_testing - mux)/stdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(data_dim, time_steps):\n",
    "    nb_filters = 200\n",
    "    \n",
    "    ip_shape = (time_steps, data_dim[0], data_dim[1], data_dim[2])\n",
    "    inputs = Input(shape = ip_shape)\n",
    "    conv_1 = Convolution3D(filters = 256, kernel_size = (1,5,1),\n",
    "                    activation='tanh', name=\"Conv1\")(inputs)\n",
    "#     maxpool_1 = MaxPooling3D(pool_size=(1,3,1), padding=\"valid\", name=\"maxpool1\")(conv_1)\n",
    "#     batch_norm1 = BatchNormalization( name = \"batch_norm_1\")(maxpool_1)\n",
    "    conv_2 = Convolution3D(filters = 128, kernel_size = (1,3,1), \n",
    "                     activation='relu', name=\"Conv2\")(conv_1)\n",
    "#     maxpool_2 = MaxPooling3D(pool_size=(1,3,1), padding=\"valid\", name=\"maxpool2\")(conv_2)\n",
    "#     batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(maxpool_2)\n",
    "    \n",
    "    conv_3 = Convolution3D(filters = 1, kernel_size = (1,3,1), \n",
    "                     activation='relu', name=\"Conv3\")(conv_2)\n",
    "    maxpool_3 = MaxPooling3D(pool_size=(1,3,1), padding=\"valid\", name=\"maxpool3\")(conv_3)\n",
    "#     batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(maxpool_2)\n",
    "    layer_shape = maxpool_3._keras_shape\n",
    "    maxpool_3 = Reshape(target_shape=(layer_shape[1], layer_shape[2]*layer_shape[3]*layer_shape[4]),\n",
    "                        name=\"maxpool3_RS\")(maxpool_3)\n",
    "    \n",
    "    flatten = Flatten()(maxpool_3)\n",
    "    \n",
    "    lstm_1 = LSTM(128, return_sequences=False, name=\"lstm_1\")(maxpool_3)\n",
    "#     lstm_2 = LSTM(128, return_sequences=\"True\", name=\"lstm_2\")(lstm_1)\n",
    "    \n",
    "    \n",
    "#     dense_1 = Dense(1024, activation='relu', name=\"Dense1\")(flatten)\n",
    "#     dropout_1 = Dropout(0.2)(dense_1)\n",
    "#     dense_2 = Dense(512, activation='relu', name=\"Dense2\")(dense_1)\n",
    "#     dropout_1 = Dropout(0.2)(dense_2)\n",
    "    output = Dense(1, name=\"output\")(flatten)\n",
    "    model = Model(inputs = inputs, output = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(X, Y, time_steps=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X)-time_steps-1):\n",
    "        a = X[i:(i+time_steps)]\n",
    "        dataX.append(a)\n",
    "        a = Y[(i+time_steps)]\n",
    "        dataY.append(a)  #dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_steps = 20\n",
    "trainX, trainY = create_dataset(X_training, Y_training, time_steps)\n",
    "valX, valY = create_dataset(X_val, Y_val, time_steps)\n",
    "testX, testY = create_dataset(X_testing, Y_testing, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 15, 76, 2) (1500,)\n",
      "(1479, 20, 15, 76, 2) (1479,)\n",
      "(1479, 20, 15, 76, 2) (1479,)\n",
      "(0,) (0,)\n"
     ]
    }
   ],
   "source": [
    "print(X_training.shape, Y_training.shape)\n",
    "print(trainX.shape, trainY.shape)\n",
    "print(testX.shape, testY.shape)\n",
    "print(valX.shape, valY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 76, 2)\n",
      "WARNING:tensorflow:From /Users/emmacreeves/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/emmacreeves/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/emmacreeves/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20, 15, 76, 2)     0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv3D)               (None, 20, 11, 76, 256)   2816      \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv3D)               (None, 20, 9, 76, 128)    98432     \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv3D)               (None, 20, 7, 76, 1)      385       \n",
      "_________________________________________________________________\n",
      "maxpool3 (MaxPooling3D)      (None, 20, 2, 76, 1)      0         \n",
      "_________________________________________________________________\n",
      "maxpool3_RS (Reshape)        (None, 20, 152)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3040)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 3041      \n",
      "=================================================================\n",
      "Total params: 104,674\n",
      "Trainable params: 104,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmacreeves/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "data_dim = (X_training.shape[1], X_training.shape[2], 2)\n",
    "print(data_dim)\n",
    "batch_size = 1\n",
    "L=len(X_training)\n",
    "n_Iter = int(L/batch_size)\n",
    "\n",
    "optimizer = optimizers.Adadelta()#, beta_1=0.9, beta_2=0.999, epsilon=1e-08)#, schedule_decay=0.004)\n",
    "model = get_model(data_dim, time_steps)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "model.summary()\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4,\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "# val_data = (np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1)), Y_val)\n",
    "# Y_train = np.reshape( Y_training, (L, 1, 1) )\n",
    "# X_train = np.reshape( X_training, (L, X_training.shape[1], 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1035 samples, validate on 444 samples\n",
      "Epoch 1/50\n",
      "1035/1035 [==============================] - 960s 927ms/step - loss: 10.6877 - val_loss: 80.4220\n",
      "Epoch 2/50\n",
      " 351/1035 [=========>....................] - ETA: 9:59 - loss: 9.8000 "
     ]
    }
   ],
   "source": [
    "model.fit(x=trainX, y=trainY, batch_size=batch_size, epochs=n_epochs, \n",
    "          validation_split=0.3,\n",
    "#           validation_data=(X_testing, Y_testing), \n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# model.save('model_1D_CNN.h5')\n",
    "\n",
    "# Load saved model\n",
    "# model = load_model('model_mlp_time_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 components, full data, n_estimators = 100, reg:gamma\n",
    "# preds = model.predict(np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1)))\n",
    "# rmse = np.sqrt(mean_squared_error(preds, Y_val)) #np.sqrt(np.mean((preds-Y_testing)**2))\n",
    "# print(\"Val RMSE:\", rmse)\n",
    "\n",
    "preds = model.predict(testX)#np.reshape(X_testing, (X_testing.shape[0], X_testing.shape[1], 1)))\n",
    "plt.plot(preds,'o',color='blue',markersize=2,mew=0.5,mec='blue',markerfacecolor='none')\n",
    "plt.plot(testY,'r',linewidth=1.0)\n",
    "plt.legend(['Precitions', 'Ground Truth'])\n",
    "plt.show()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(preds, testY)) #np.sqrt(np.mean((preds-Y_testing)**2))\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
